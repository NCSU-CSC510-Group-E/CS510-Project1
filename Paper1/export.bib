@misc{RefWorks:doc:5a694cc8e4b0e9de2dfe54e1,
	title = 	 {out}
}
@inproceedings{RefWorks:doc:5a6e62a0e4b0d609eec79a2f,
	author={Maria Pera and Yiu-Kai Ng},
	year={Aug 22, 2011},
	title={With a Little Help From My Friends Generating Personalized Book Recommendations Using Data Extracted from a Social Website},
	series={WI-IAT '11},
	publisher={IEEE Computer Society},
	volume={1},
	pages={96-99},
	abstract={With the large amount of books available nowadays, users are overwhelmed with choices when they attempt to find books of interest. While existing book recommendation systems, which are based on either collaborative filtering, content-based, or hybrid methods, suggest books (among the millions available) that might be appealing to the users, their recommendations are not personalized enough to meet users' expectations due to their collective assumption on group preference and/or exact content matching, which is a failure. To address this problem, we have developed PReF, a Personalized Recommender that relies on Friendships established by user son a social website, such as Library Thing, to make book recommendations tailored to individual users. In selecting books to be recommended to a user U, who is interested in a book B, PReF (i) considers books belonged to U's friends, (ii) applies word-correlation factors to disclose books similar in contents to B, (iii)depends on the ratings given to books by U's friends to identify highly-regarded books, and (iv) determine show reliable individual friends of U are in providing books from their own catalogs (that are similar in content to B)to be recommended. We have conducted an empirical study and verified that (i) relying on data extracted from social websites improves the effectiveness of book recommenders and (ii) PReF outperforms the recommenders employed by Amazon and Library Thing.},
	language={English},
	url={http://dl.acm.org/citation.cfm?id=2052431},
	doi={10.1109/WI-IAT.2011.9}
}
@inbook{RefWorks:doc:5a6e629de4b05a778a121d60,
	author={Maria Pera and Nicole Condie and Yiu-Kai Ng},
	year={2011},
	title={Personalized Book Recommendations Created by Using Social Media Data},
	series={Web Information Systems Engineering – WISE 2010 Workshops},
	publisher={Springer Berlin Heidelberg},
	address={Berlin, Heidelberg},
	volume={6724},
	pages={390-403},
	abstract={Book recommendation systems can benefit commercial websites, social media sites, and digital libraries, to name a few, by alleviating the knowledge acquisition process of users who look for books that are appealing to them. Even though existing book recommenders, which are based on either collaborative filtering, text content, or the hybrid approach, aid users in locating books (among the millions available), their recommendations are not personalized enough to meet users’ expectations due to their collective assumption on group preference and/or exact content matching, which is a failure. To address this problem, we have developed PBRecS, a book recommendation system that is based on social interactions and personal interests to suggest books appealing to users. PBRecS relies on the friendships established on a social networking site, such as LibraryThing, to generate more personalized suggestions by including in the recommendations solely books that belong to a user’s friends who share common interests with the user, in addition to applying word-correlation factors for partially matching book tags to disclose books similar in contents. The conducted empirical study on data extracted from LibraryThing has verified (i) the effectiveness of PBRecS using social-media data to improve the quality of book recommendations and (ii) that PBRecS outperforms the recommenders employed by Amazon and LibraryThing.},
	isbn={9783642243950},
	language={English},
	doi={10.1007/978-3-642-24396-7_31}
}
@misc{RefWorks:doc:5a6e629be4b05d2b53fd1ec8,
	author = 	 {student of Graduate Institute of Library and Information Studies and NTNU},
	title = 	 {Library Book Recommendations Based on Latent Topic Aggregation},
	abstract = 	 {Abstract.  During  recent  years,  how  to  provide  personalized  services  has become an important research issue in library services. The libraries provide more and more personalized services such as customized web interface and reading suggestions. In the traditional approaches, the features of the books that a reader likes are used to construct the profile of the reader to support recommendation of books such as query keywords. But with the fact of the huge holdings in the libraries, the librarians need to effectively help the readers to find the books of interest. Collaborative filtering (CF) is a way to make it possible by use patron's circulation logs which contain their borrow history as favorite readings. In this paper, we first use Latent Dirichlet Allocation to find the latent topics existing in the circulation logs, then we combine patron reading histories with the generated latent topics to produce a suggestion list for the patron. With the elaborated experiments demonstrated in this paper, it showed good results from the volunteers' feedback.}
}
@article{RefWorks:doc:5a6e6299e4b03ce0ba201546,
	author={Linyuan Lü and Matúš Medo and Chi Ho Yeung and Zi-Ke Zhang and Yi-Cheng Zhang and Tao Zhou},
	year={2012},
	month={Oct 1,},
	title={Comparative Evaluation for Recommender Systems for Book Recommendations},
	journal={Physics Reports},
	volume={519},
	number={2},
	pages={1},
	abstract={The ongoing rapid expansion of the Internet greatly increases the necessity of effective recommender systems for filtering the abundant information. Extensive research for recommender systems is conducted by a broad range of communities including social and computer scientists, physicists, and interdisciplinary researchers. Despite substantial theoretical and practical achievements, unification and comparison of different approaches are lacking, which impedes further advances. In this article, we review recent developments in recommender systems and discuss the major challenges. We compare and evaluate available algorithms and examine their roles in the future developments. In addition to algorithms, physical aspects are described to illustrate macroscopic behavior of recommender systems. Potential impacts and future directions are discussed. We emphasize that recommendation has great scientific depth and combines diverse research fields which makes it interesting for physicists as well as interdisciplinary researchers.},
	isbn={0370-1573},
	language={English},
	url={https://www.sciencedirect.com/science/article/pii/S0370157312000828},
	doi={10.1016/j.physrep.2012.02.006}
}
@inproceedings{RefWorks:doc:5a6e6294e4b0645cd2d33e74,
	author={Anand Shanker Tewari and Abhay Kumar and Asim Gopal Barman},
	year={2014},
	title={Book recommendation system based on combine features of content based filtering, collaborative filtering and association rule mining},
	publisher={IEEE},
	pages={500-503},
	abstract={Recommendation systems are widely used to recommend products to the end users that are most appropriate. Online book selling websites now-a-days are competing with each other by many means. Recommendation system is one of the stronger tools to increase profit and retaining buyer. The book recommendation system must recommend books that are of buyer's interest. This paper presents book recommendation system based on combined features of content filtering, collaborative filtering and association rule mining.},
	language={English},
	url={http://ieeexplore.ieee.org/document/6779375},
	doi={10.1109/IAdCC.2014.6779375}
}
@article{RefWorks:doc:5a6e5748e4b0d609eec798df,
	author={Jey Han Lau and Timothy Baldwin},
	year={2016},
	month={Jul 18,},
	title={An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation},
	note={Word2vec vs doc2vec. Generally says dbow method of doc preforms better than word, but the significance of how much better depends on the size of the document.},
	abstract={Recently, Le and Mikolov (2014) proposed doc2vec as an extension to word2vec (Mikolov et al., 2013a) to learn document-level embeddings. Despite promising results in the original paper, others have struggled to reproduce those results. This paper presents a rigorous empirical evaluation of doc2vec over two tasks. We compare doc2vec to two baselines and two state-of-the-art document embedding methodologies. We found that doc2vec performs robustly when using models trained on large external corpora, and can be further improved by using pre-trained word embeddings. We also provide recommendations on hyper-parameter settings for general purpose applications, and release source code to induce document embeddings using our trained doc2vec models.},
	language={English},
	url={http://arxiv.org/abs/1607.05368}
}
@article{RefWorks:doc:5a6e5748e4b0d609eec798dd,
	author={Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg Corrado and Jeffrey Dean},
	year={2013},
	month={Oct 16,},
	title={Distributed Representations of Words and Phrases and their Compositionality},
	note={Skip-gram model, Negative Sampling},
	abstract={The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
	language={English},
	url={http://arxiv.org/abs/1310.4546}
}
@article{RefWorks:doc:5a6e5747e4b0d609eec798db,
	author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
	year={2013},
	month={Jan 16,},
	title={Efficient Estimation of Word Representations in Vector Space},
	note={Introduction to word2doc. See ‘distributed representations of words and phrases’ for more info.},
	abstract={We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	language={English},
	url={http://arxiv.org/abs/1301.3781}
}
@article{RefWorks:doc:5a6e5746e4b0d609eec798d9,
	author={Mojtaba Zahedi Amiri and Abdullah Shobi},
	year={2017},
	month={Jul 13,},
	title={A Link Prediction Strategy for Personalized Tweet
Recommendation through Doc2Vec Approach},
	journal={Research in Economics and Management},
	volume={2},
	number={4},
	pages={14},
	note={Doc2vec works better than other ‘approaches’ with tweets},
	abstract={Nowadays with growth of using Internet as a principle way of communication, likes different social
medias channels (Twitter, Facebook, etc.) and also access to huge amount of information like News,
there appear a main research subject to help users to find his/her interests among vast amount of
relevant and irrelevant information. Recommender systems are helped to handle information overload
problem and in this paper we introduce our Tweet Recommendation System that implement user’s
Twitter information (Tweets, Retweet, Like,...) as a source of user’s information. In this work the
semantic of tweets that regard as a User’s Explicit Interests (e.g., person, events, product mentioned in
user’s tweets) are identified with the Doc2vec approach and recommend similar tweets through
link-prediction strategy. The experiment results show that Doc2Vec approach is a better approach than
the other previous approaches.},
	isbn={2470-4407},
	language={English},
	url={http://scholink.org/ojs/index.php/rem/article/view/1018/1165}
}
@article{RefWorks:doc:5a6e5746e4b0d609eec798d7,
	author={Quoc V. Le and Tomas Mikolov},
	year={2014},
	month={May 16,},
	title={Distributed Representations of Sentences and Documents},
	note={Paragraph vector (doc2vec)},
	abstract={Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
	language={English},
	url={http://arxiv.org/abs/1405.4053}
}
@misc{RefWorks:doc:5a6cba52e4b08f847f724080,
	author = 	 {Dat Quoc Nguyen and Richard Billingsley and Lan Du Mark Johnson and 1 D C and M U and S and A 2 S F I and S F and N M and USA dat.nguyen@students.mq.edu.au and richard.billingsley and lan.du and mark.johnson@mq.edu.au},
	title = 	 {Improving Topic Models with Latent Feature Word Representations},
	volume = 	 {3},
	abstract = 	 {Probabilistic topic models are widely used to discover latent topics in document collec- tions, while latent feature vector representa- tions of words have been used to obtain high performance in many NLP tasks. In this pa- per, we extend two different Dirichlet multino- mial topic models by incorporating latent fea- ture vector representations of words trained on very large corpora to improve the word-topic mapping learnt on a smaller corpus.  Exper- imental results show that by using informa- tion from the external corpora, our new mod- els produce signiﬁcant improvements on topic coherence, document clustering and document classiﬁcation tasks, especially on datasets with few or short documents.}
}
@misc{RefWorks:doc:5a6cba52e4b05d2b53fcf8dd,
	author = 	 {Word embedding and also known as word representation and plays an increasingly vital role in building continuous word vec- tors based on their contexts in a large corpus. Word em- bedding captures both semantic and syntactic information of words and can be used to measure word similarities and which are widely used in various, I R and NLP tasks. Most word embedding methods assume each word preserves a single vector and which is problematic due to homonymy and polysemy. Multi-prototype vector space models (Reisinger and Mooney 2010) were proposed to cluster contexts of a word into groups and then generate a dis- tinct prototype vector for each cluster. Following this idea and (Huang  2012) proposed multi-prototype word embed-},
	title = 	 {Topical Word Embeddings},
	abstract = 	 {Most word embedding models typically represent each word using a single vector, which makes these mod- els indiscriminative for ubiquitous homonymy and pol- ysemy. In order to enhance discriminativeness, we em- ploy latent topic models to assign topics for each word in the text corpus, and learn topical word embeddings (TWE) based on both words and their topics. In this way, contextual word embeddings can be ﬂexibly ob- tained to measure contextual word similarity. We can also build document representations, which are more expressive  than  some  widely-used  document  models such as latent topic models. In the experiments, we eval- uate the TWE models on two tasks, contextual word similarity and text classiﬁcation. The experimental re- sults show that our models outperform typical word em- bedding models including the multi-prototype version on contextual word similarity, and also exceed latent topic models and other representative document mod- els on text classiﬁcation. The source code of this pa- per can be obtained from https://github.com/largelymfs/ topical word embeddings.}
}
@phdthesis{RefWorks:doc:5a694ccae4b0f9841ef6f0d9,
	author={Penghao Wang},
	year={2017},
	month={Jan 1,},
	title={Extract Restaurant Aspect Words by Using Word2vec Model from Yelp Reviews},
	abstract={Many customers use Yelp restaurant reviews to determine where they will eat. However, it is almost impossible for users to read all the reviews because of the large number of reviews. Customers usually have different concerns about restaurants like ambiance, service, and food quality. Providing customer reviews that concentrate on the aspects that they are concerned with would save customers time and help them to find better restaurants. This thesis is an investigation into selecting such useful aspects. To achieve that, one needs to detect which aspects are mentioned in the review. In this study, the researcher used a Word2vec model to detect the aspect words and tested the performance of the model on the manually labeled data and compared the results to a statistical model. The author presented three tasks the Word2vec model could do: (1) detecting food categories, (2) detecting informal words, and (3) detecting typos and abbreviations. As a result, the author found the Word2vec model yielded better performance results than the statistical topic model on the aspect extraction task.},
	language={English},
	url={https://search.proquest.com/docview/1947271871}
}
@article{RefWorks:doc:5a694cc9e4b0e9de2dfe54e2,
	author={Chahinez Benkoussas and Patrice Bellot},
	year={2015},
	title={Information Retrieval and Graph Analysis Approaches for Book Recommendation},
	journal={The Scientific World Journal},
	volume={2015},
	pages={1-8},
	abstract={  A combination of multiple information retrieval approaches is proposed for the purpose of book recommendation. In this paper, book recommendation is based on complex user's query. We used different theoretical retrieval models: probabilistic as InL2 (Divergence from Randomness model) and language model and tested their interpolated combination. Graph analysis algorithms such as PageRank have been successful in Web environments. We consider the application of this algorithm in a new retrieval approach to related document network comprised of social links. We called Directed Graph of Documents (DGD) a network constructed with documents and social information provided from each one of them. Specifically, this work tackles the problem of book recommendation in the context of INEX (Initiative for the Evaluation of XML retrieval) Social Book Search track. A series of reranking experiments demonstrate that combining retrieval models yields significant improvements in terms of standard ranked retrieval metrics. These results extend the applicability of link analysis algorithms to different environments.},
	isbn={2356-6140},
	language={English},
	url={https://search.proquest.com/docview/1721316825},
	doi={10.1155/2015/926418}
}
